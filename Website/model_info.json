{
    "FNN_model": {
    "type": "Deep Learning",
    "architecture": "128-64-32-7",
    "training_date": "2023-05-15",
    "accuracy": 0.8436,
    "description": "Feedforward Neural Network",
    "metrics": {
      "accuracy": 0.8436,
      "precision": 0.89,
      "recall": 0.81,
      "f1_score": 0.76
    },
    "confusion_matrix": [
      [472, 1, 4, 0, 0, 0],
      [0, 203, 0, 2, 0, 0],
      [2, 0, 200, 0, 8, 0],
      [0, 13, 0, 210, 0, 0],
      [1, 0, 0, 0, 221, 0],
      [1, 11, 0, 3, 217, 4]
    ]
  },
  "ImprovedFNN_model": {
    "type": "Deep Learning",
    "architecture": "128-64-32-7",
    "training_date": "2023-05-15",
    "accuracy": 0.83,
    "description": "Feedforward Neural Network with dropout layers for regularization",
    "metrics": {
      "accuracy": 0.83,
      "precision": 0.89,
      "recall": 0.81,
      "f1_score": 0.76
    },
    "confusion_matrix": [
      [472, 1, 4, 0, 0, 0],
      [0, 203, 0, 2, 0, 0],
      [2, 0, 200, 0, 8, 0],
      [0, 13, 0, 210, 0, 0],
      [1, 0, 0, 0, 221, 0],
      [1, 11, 0, 3, 217, 4]
    ]
  },
  "CNN_model": {
    "type": "Deep Learning",
    "architecture": "Conv1D(64)-MaxPool-Dense(32)-7",
    "training_date": "2023-05-15",
    "accuracy": 0.82,
    "description": "Basic 1D Convolutional Neural Network for sequence classification",
    "metrics": {
      "accuracy": 0.82,
      "precision": 0.78,
      "recall": 0.80,
      "f1_score": 0.76
    },
    "confusion_matrix": [
      [475, 1, 1, 0, 0, 0],
      [1, 202, 0, 2, 0, 0],
      [5, 0, 193, 0, 9, 3],
      [0, 14, 0, 208, 0, 1],
      [2, 0, 0, 2, 205, 13],
      [1, 11, 0, 6, 208, 10]
    ]
  },
  "AdvancedCNN_model": {
    "type": "Deep Learning",
    "architecture": "Conv1D(128)-Conv1D(64)-GlobalAvgPool-7",
    "training_date": "2023-05-15",
    "accuracy": 0.81,
    "description": "Advanced CNN with two convolutional layers and global average pooling",
    "metrics": {
      "accuracy": 0.81,
      "precision": 0.78,
      "recall": 0.79,
      "f1_score": 0.78
    },
    "confusion_matrix": [
      [452, 19, 6, 0, 0, 0],
      [3, 201, 1, 0, 0, 0],
      [8, 0, 186, 0, 0, 16],
      [0, 12, 0, 211, 0, 0],
      [2, 1, 0, 3, 122, 94],
      [1, 7, 0, 13, 114, 101]
    ]
  },
  "LSTM_model": {
    "type": "Deep Learning",
    "architecture": "LSTM(64)-Dense(32)-7",
    "training_date": "2023-05-15",
    "accuracy": 0.80,
    "description": "Long Short-Term Memory network for sequence classification",
    "metrics": {
      "accuracy": 0.80,
      "precision": 0.77,
      "recall": 0.78,
      "f1_score": 0.75
    },
    "confusion_matrix": [
      [472, 5, 0, 0, 0, 0],
      [6, 198, 0, 1, 0, 0],
      [13, 0, 185, 0, 12, 0],
      [0, 13, 0, 207, 3, 0],
      [0, 0, 1, 17, 173, 31],
      [0, 9, 1, 22, 176, 28]
    ]
  },
  "GRU_model": {
    "type": "Deep Learning",
    "architecture": "GRU(64)-Dense(32)-7",
    "training_date": "2023-05-15",
    "accuracy": 0.81,
    "description": "Gated Recurrent Unit network for sequence processing",
    "metrics": {
      "accuracy": 0.81,
      "precision": 0.79,
      "recall": 0.80,
      "f1_score": 0.79
    },
    "confusion_matrix": [
      [435, 11, 31, 0, 0, 0],
      [4, 199, 0, 2, 0, 0],
      [3, 0, 196, 0, 11, 0],
      [0, 5, 0, 213, 3, 2],
      [0, 0, 0, 1, 146, 75],
      [0, 0, 0, 1, 151, 84]
    ]
  },
  "KNN": {
    "type": "Machine Learning",
    "description": "K-Nearest Neighbors classifier with default parameters",
    "training_date": "2023-05-15",
    "accuracy": 0.82,
    "description": "Instance-based learning algorithm that stores training examples and predicts based on the majority class of the k nearest neighbors",
    "metrics": {
      "accuracy": 0.82,
      "precision": 0.82,
      "recall": 0.82,
      "f1_score": 0.82
    },
    "confusion_matrix": [
      [470, 0, 0, 0, 0, 0],
      [0, 201, 0, 0, 0, 0],
      [1, 0, 97, 0, 0, 149],
      [0, 0, 0, 234, 2, 0],
      [0, 0, 0, 5, 200, 3],
      [0, 0, 109, 1, 7, 94]
    ]
  },
  "Naive_Bayes": {
    "type": "Machine Learning",
    "description": "Gaussian Naive Bayes classifier",
    "training_date": "2023-05-15",
    "accuracy": 0.79,
    "description": "Probabilistic classifier based on applying Bayes' theorem with strong (naive) independence assumptions between the features",
    "metrics": {
      "accuracy": 0.79,
      "precision": 0.77,
      "recall": 0.79,
      "f1_score": 0.77
    },
    "confusion_matrix": [
      [470, 0, 0, 0, 0, 0],
      [15, 183, 3, 0, 0, 0],
      [1, 12, 117, 0, 22, 95],
      [23, 0, 0, 212, 1, 0],
      [0, 0, 2, 25, 181, 0],
      [0, 13, 100, 14, 12, 72]
    ]
  },
  "Logistic_Regression": {
    "type": "Machine Learning",
    "description": "Logistic Regression with default solver",
    "training_date": "2023-05-15",
    "accuracy": 0.35,
    "description": "Linear model for classification that estimates probabilities using a logistic function",
    "metrics": {
      "accuracy": 0.35,
      "precision": 0.28,
      "recall": 0.35,
      "f1_score": 0.22
    },
    "confusion_matrix": [
      [470, 0, 0, 0, 0, 0],
      [181, 0, 0, 0, 0, 20],
      [207, 0, 0, 0, 0, 40],
      [236, 0, 0, 0, 0, 0],
      [163, 0, 0, 0, 45, 0],
      [179, 0, 0, 0, 0, 32]
    ]
  },
  "Random_Forest": {
    "type": "Machine Learning",
    "description": "Random Forest classifier with default parameters",
    "training_date": "2023-05-15",
    "accuracy": 0.83,
    "description": "Ensemble learning method that constructs multiple decision trees and outputs the mode of the classes of the individual trees",
    "metrics": {
      "accuracy": 0.83,
      "precision": 0.82,
      "recall": 0.83,
      "f1_score": 0.82
    },
    "confusion_matrix": [
      [470, 0, 0, 0, 0, 0],
      [6, 195, 0, 0, 0, 0],
      [0, 19, 115, 0, 7, 106],
      [5, 0, 0, 213, 18, 0],
      [0, 0, 0, 0, 208, 0],
      [0, 11, 91, 0, 4, 105]
    ]
  },
  "SVC_Linear": {
    "type": "Machine Learning",
    "description": "Support Vector Classifier with linear kernel",
    "training_date": "2023-05-15",
    "accuracy": 0.60,
    "description": "Support Vector Machine classifier using a linear kernel to find the optimal separating hyperplane",
    "metrics": {
      "accuracy": 0.60,
      "precision": 0.68,
      "recall": 0.60,
      "f1_score": 0.54
    },
    "confusion_matrix": [
      [470, 0, 0, 0, 0, 0],
      [85, 67, 5, 25, 7, 12],
      [102, 0, 11, 14, 4, 116],
      [11, 0, 0, 206, 0, 19],
      [48, 1, 0, 18, 66, 75],
      [77, 1, 0, 10, 3, 120]
    ]
  },
  "SVC_RBF": {
    "type": "Machine Learning",
    "description": "Support Vector Classifier with RBF kernel",
    "training_date": "2023-05-15",
    "accuracy": 0.79,
    "description": "Support Vector Machine classifier using Radial Basis Function kernel to handle non-linear decision boundaries",
    "metrics": {
      "accuracy": 0.79,
      "precision": 0.87,
      "recall": 0.79,
      "f1_score": 0.74
    },
    "confusion_matrix": [
      [470, 0, 0, 0, 0, 0],
      [28, 153, 0, 0, 0, 20],
      [0, 0, 6, 1, 8, 232],
      [16, 0, 0, 218, 2, 0],
      [0, 0, 0, 8, 200, 0],
      [0, 0, 0, 8, 14, 189]
    ]
  },
  "SVC_Optimized": {
    "type": "Machine Learning",
    "description": "SVC (RBF) with hyperparameter tuning",
    "training_date": "2023-05-15",
    "accuracy": 0.84,
    "description": "Optimized Support Vector Machine classifier with RBF kernel using grid search for hyperparameter tuning",
    "metrics": {
      "accuracy": 0.84,
      "precision": 0.85,
      "recall": 0.84,
      "f1_score": 0.82
    },
    "confusion_matrix": [
      [470, 0, 0, 0, 0, 0],
      [1, 200, 0, 0, 0, 0],
      [0, 0, 44, 0, 0, 203],
      [0, 0, 0, 236, 0, 0],
      [0, 0, 0, 5, 203, 0],
      [0, 0, 38, 0, 5, 168]
    ]
  },
  "SGD_Classifier": {
    "type": "Machine Learning",
    "description": "Stochastic Gradient Descent Classifier",
    "training_date": "2023-05-15",
    "accuracy": 0.28,
    "description": "Linear classifier that implements regularized linear models with stochastic gradient descent learning",
    "metrics": {
      "accuracy": 0.28,
      "precision": 0.19,
      "recall": 0.28,
      "f1_score": 0.22
    },
    "confusion_matrix": [
      [260, 99, 6, 0, 0, 105],
      [85, 98, 0, 0, 0, 18],
      [105, 109, 0, 14, 14, 5],
      [116, 32, 0, 0, 88, 0],
      [83, 32, 0, 16, 77, 0],
      [94, 85, 0, 16, 13, 3]
    ]
  },
  "Decision_Tree": {
    "type": "Machine Learning",
    "description": "Decision Tree Classifier with default parameters",
    "training_date": "2023-05-15",
    "accuracy": 0.28,
    "description": "Non-parametric supervised learning method that learns simple decision rules inferred from the data features",
    "metrics": {
      "accuracy": 0.28,
      "precision": 0.19,
      "recall": 0.28,
      "f1_score": 0.22
    },
    "confusion_matrix": [
      [260, 99, 6, 0, 0, 105],
      [85, 98, 0, 0, 0, 18],
      [105, 109, 0, 14, 14, 5],
      [116, 32, 0, 0, 88, 0],
      [83, 32, 0, 16, 77, 0],
      [94, 85, 0, 16, 13, 3]
    ]
  }
}